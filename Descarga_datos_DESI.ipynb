{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55bcec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from astropy.io import fits\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.table import Table\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from astropy.utils.data import get_pkg_data_filename\n",
    "from astropy.convolution import convolve, Gaussian1DKernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff20670d",
   "metadata": {},
   "source": [
    "### Obtenemos los enlaces de cada archivo y creamos un archivo de texto con ellos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bab2970",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://data.desi.lbl.gov/public/edr/spectro/redux/fuji/healpix/sv3/dark/\"\n",
    "\n",
    "# Obtengo las carpetas y archivos FITS desde la página HTML\n",
    "def get_folders_and_fits(url):\n",
    "    response = requests.get(url)\n",
    "    # Verifica si la respuesta falló y muestra un mensaje\n",
    "    if response.status_code != 200:\n",
    "        print(\"Verifica tu conexión a Internet para asegurarte de que esté funcionando correctamente.\")\n",
    "        return [], []\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    folders = []\n",
    "    fits_files = []\n",
    "\n",
    "    # Busco todos los enlaces en la página\n",
    "    for link in soup.find_all('a', href=True):\n",
    "        href = link['href']\n",
    "        text = link.text\n",
    "        if href.endswith('/') and not text.startswith('..') and not href.endswith('logs/'):\n",
    "            # Es una carpeta\n",
    "            folder_name = text.rstrip('/')\n",
    "            folders.append(folder_name)\n",
    "        elif text.startswith('redrock-sv3-dark-') or text.startswith('coadd-sv3-dark-'):\n",
    "            # Es un archivo FITS\n",
    "            fits_files.append(text)\n",
    "    \n",
    "    return folders, fits_files\n",
    "\n",
    "# Explorar los archivos de la ultima, tercera, capa. Aqui estan los .fits\n",
    "def explore_third_layer_folders(url):\n",
    "    _ , fits_files = get_folders_and_fits(url)\n",
    "    nstype=[]\n",
    "    # FITS coadd y redrock\n",
    "    for fits_file in tqdm(fits_files):\n",
    "        with open('urlspectra.txt', 'a') as archivo:\n",
    "            if fits_file.startswith('redrock-sv3-dark-'): \n",
    "                red_rock_fits_urls = url + fits_file  #aqui obtengo todos los urls que me llevan a todos los fits de redrock\n",
    "                archivo.write(red_rock_fits_urls+\"\\n\")\n",
    "            if fits_file.startswith('coadd-sv3-dark-'): \n",
    "                coadd_fits_urls = url + fits_file\n",
    "                archivo.write(coadd_fits_urls+\"\\n\")\n",
    "        print(\"copiado\")\n",
    "            \n",
    "\n",
    "    \n",
    "# Explorar las carpetas de la segunda capa 10016/ 10145/ etc/\n",
    "def explore_second_layer_folders(url):\n",
    "    folders, _ = get_folders_and_fits(url)\n",
    "    for folder in folders:\n",
    "        folder_url = url + folder + '/'\n",
    "        explore_third_layer_folders(folder_url)                \n",
    "                \n",
    "# Explora las carpetas de la primera capa: 100/ 101/ etc/\n",
    "def explore_first_layer_folders(url):\n",
    "    folders, _ = get_folders_and_fits(url)\n",
    "    for folder in folders:\n",
    "        folder_url = url + folder + '/'\n",
    "        explore_second_layer_folders(folder_url)\n",
    "        \n",
    "        \n",
    "# Comienzo la exploración desde la URL base en la primera capa\n",
    "explore_first_layer_folders(base_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bc2c14",
   "metadata": {},
   "source": [
    "### Leemos el archivo de texto con los enlaces, bajamos los espectros y los almacenamos en nuevos conjuntos de archivos .fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3a39261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copiado: 1\n",
      "Copiado: 2\n",
      "Copiado: 3\n",
      "Copiado: 4\n",
      "Copiado: 5\n",
      "Copiado: 6\n",
      "Copiado: 7\n",
      "Copiado: 8\n",
      "Copiado: 9\n",
      "Copiado: 10\n",
      "Copiado: 11\n",
      "Copiado: 12\n",
      "Copiado: 13\n",
      "Copiado: 14\n",
      "Copiado: 15\n",
      "Copiado: 16\n",
      "Copiado: 17\n",
      "Copiado: 18\n"
     ]
    }
   ],
   "source": [
    "with open('urlspectra.txt', 'r') as archivo:\n",
    "    n=0\n",
    "    STYPE=[]\n",
    "    Z=[]\n",
    "    TARGET=[]\n",
    "    BFLUX=[]\n",
    "    RFLUX=[]\n",
    "    ZFLUX=[]\n",
    "    lineas = archivo.readlines()  # Lee todas las líneas del archivo y las almacena en una lista\n",
    "    for i in range(720,len(lineas)-2, 2): #Este rango va de el primero al tercer fits es decir los primeros 20 fits con 10 readrock y 10\n",
    "        # Imprime dos líneas a la vez (par de líneas)\n",
    "        stype=[]\n",
    "        z=[]\n",
    "        target=[]\n",
    "        Bflux=[]\n",
    "        Rflux=[]\n",
    "        Zflux=[]\n",
    "        \n",
    "        if i + 1 < len(lineas):\n",
    "            coadd=fits.open(lineas[i])\n",
    "            readrock=fits.open(lineas[i + 1])\n",
    "            read_readrock=Table.read(readrock, hdu=1)\n",
    "            read_coadd = Table.read(coadd, hdu=1) \n",
    "            targetID_coadd=read_coadd['TARGETID'].data #Target ID lista # Redshift lista\n",
    "            spectype=read_readrock['SPECTYPE'].data    # Tipo espectral lista\n",
    "            Z_r=read_readrock['Z'].data # \n",
    "            for j in range(len(targetID_coadd)): #elimina los targetID negativos\n",
    "                if targetID_coadd[j]>=0:\n",
    "                    stype.append(spectype[j])\n",
    "                    z.append(Z_r[j])\n",
    "                    target.append(targetID_coadd[j])\n",
    "                    Bflux.append(coadd[4].data[j])\n",
    "                    Rflux.append(coadd[9].data[j])\n",
    "                    Zflux.append(coadd[14].data[j])     \n",
    "            #une los espectros de cada archivo fits\n",
    "            TARGET+=target\n",
    "            Z+=z\n",
    "            STYPE+=stype\n",
    "            BFLUX+= Bflux\n",
    "            RFLUX+= Rflux\n",
    "            ZFLUX+= Zflux\n",
    "            n+=1\n",
    "            print(\"Copiado: \"+str(n))\n",
    "            \n",
    "    # Define los tipos de datos\n",
    "    dtype = [('SPECTYPE', 'S7'), ('Z', 'float'), ('TARGETID', 'float')]\n",
    "    # Crea un arreglo estructurado de NumPy\n",
    "    data = np.zeros(len(Z), dtype=dtype)\n",
    "    data['SPECTYPE'] = STYPE\n",
    "    data['Z'] = Z\n",
    "    data['TARGETID'] = TARGET\n",
    "    # Crea una tabla FITS usando fits.BinTableHDU\n",
    "    hdu = fits.BinTableHDU.from_columns(data)\n",
    "    # Crea los arreglos para \n",
    "    data_Bflux = np.array(BFLUX, dtype=np.float32)\n",
    "    data_Rflux = np.array(RFLUX, dtype=np.float32)\n",
    "    data_Zflux = np.array(ZFLUX, dtype=np.float32)\n",
    "    # Crea un objeto ImageHDU\n",
    "    hdub = fits.ImageHDU(data_Bflux)\n",
    "    hdur = fits.ImageHDU(data_Rflux)\n",
    "    hduz = fits.ImageHDU(data_Zflux)\n",
    "    # Establece el nombre del HDU como 'B_FLUX'\n",
    "    hdub.name = 'B_FLUX'\n",
    "    hdur.name = 'R_FLUX'\n",
    "    hduz.name = 'Z_FLUX'\n",
    "    #Agrega al fits.\n",
    "    nombre_archivo = 'DataDESI.fits'\n",
    "    hdulist = fits.open(nombre_archivo, mode='append')\n",
    "    hdulist.append(hdu)\n",
    "    hdulist.append(hdub)\n",
    "    hdulist.append(hdur)\n",
    "    hdulist.append(hduz)\n",
    "    hdulist.close() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed0ff38-46b1-454f-98d5-12a1c2ed449b",
   "metadata": {},
   "source": [
    "### Este es el nombre de las carpetas que condensan todos los datos originales de la base de datos de DESI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f03f38-5910-4b69-8641-8d0faa6419f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "['DataDESI_1_36.fits', 'DataDESI_37_72.fits', 'DataDESI_73_108.fits', 'DataDESI_109_144.fits', 'DataDESI_145_180.fits', 'DataDESI_181_216.fits'\n",
    ", 'DataDESI_217_252.fits', 'DataDESI_253_288.fits', 'DataDESI_289_324.fits', 'DataDESI_325_360.fits', 'DataDESI_361_379.fits']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b5617c-be12-4d80-9478-eeb51e3780d6",
   "metadata": {},
   "source": [
    "### Exploracion de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae4d5936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: DataDESI_361_379.fits\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU       4   ()      \n",
      "  1                1 BinTableHDU     14   21772R x 3C   [7A, D, D]   \n",
      "  2  B_FLUX        1 ImageHDU         8   (2751, 21772)   float32   \n",
      "  3  R_FLUX        1 ImageHDU         8   (2326, 21772)   float32   \n",
      "  4  Z_FLUX        1 ImageHDU         8   (2881, 21772)   float32   \n",
      "21772\n"
     ]
    }
   ],
   "source": [
    "from astropy.table import Table\n",
    "espc = fits.open('DataDESI_361_379.fits')\n",
    "espc.info()\n",
    "print(len(espc[2].data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c00dee5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El elemento 'a' aparece 19364 veces en el NumPy array.\n"
     ]
    }
   ],
   "source": [
    "conteo_a = np.sum(Table.read(espc, hdu=1)[\"SPECTYPE\"].data == 'GALAXY')\n",
    "\n",
    "print(\"El elemento 'a' aparece\", conteo_a, \"veces en el NumPy array.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4eec32df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El elemento 'a' aparece 970 veces en el NumPy array.\n"
     ]
    }
   ],
   "source": [
    "conteo_a = np.sum(Table.read(espc, hdu=1)[\"SPECTYPE\"].data == 'STAR')\n",
    "\n",
    "print(\"El elemento 'a' aparece\", conteo_a, \"veces en el NumPy array.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a8fc8aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El elemento 'a' aparece 1438 veces en el NumPy array.\n"
     ]
    }
   ],
   "source": [
    "conteo_a = np.sum(Table.read(espc, hdu=1)[\"SPECTYPE\"].data == 'QSO')\n",
    "\n",
    "print(\"El elemento 'a' aparece\", conteo_a, \"veces en el NumPy array.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f39fdc9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPECTYPE           Z                   TARGETID       \n",
      "-------- ---------------------- ----------------------\n",
      "  GALAXY     0.8096589134393345  3.963312758430371e+16\n",
      "  GALAXY     0.9282989193404377  3.963313202187755e+16\n",
      "  GALAXY     1.5251344667187916  3.963313643848008e+16\n",
      "  GALAXY    0.25679214910795595  3.963313202187697e+16\n",
      "  GALAXY     0.7563224362494237  3.963312758430276e+16\n",
      "    STAR -0.0011996796199236536 3.9633136442672536e+16\n",
      "     QSO     1.1807410029513217  3.963313202187771e+16\n",
      "     QSO     0.9350379047671412 3.9633127584302856e+16\n",
      "  GALAXY     0.8423552934538804 3.9633127584303496e+16\n",
      "  GALAXY     0.9259450310404335   3.96331320218769e+16\n",
      "     ...                    ...                    ...\n",
      "  GALAXY     0.9553647756528504  3.963315407972351e+16\n",
      "  GALAXY     0.7574984894419702  3.963315407972291e+16\n",
      "  GALAXY     1.4918708566290344  6.160939107074703e+17\n",
      "  GALAXY     0.4213718959427256 3.9633158404051016e+16\n",
      "     QSO     1.1677343519034808   3.96331540839138e+16\n",
      "    STAR -0.0019956912923479522  3.963315407972277e+16\n",
      "  GALAXY     1.1009701727348211 3.9633158404051256e+16\n",
      "    STAR -0.0019956912923479522 3.9633154079723704e+16\n",
      "  GALAXY    0.36303013683445023 3.9633158408241336e+16\n",
      "    STAR -0.0019956912923479522  3.963315407972351e+16\n",
      "  GALAXY     0.6907269180797337   3.96331540839142e+16\n",
      "Length = 21772 rows\n"
     ]
    }
   ],
   "source": [
    "print(Table.read(espc, hdu=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "687a6911-b470-4480-8554-4203840836c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.80965891,  0.92829892,  1.52513447, ...,  0.36303014,\n",
       "       -0.00199569,  0.69072692])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Table.read(espc, hdu=1)['Z'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0b2affb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21772\n",
      "2881\n"
     ]
    }
   ],
   "source": [
    "print(len(espc[2].data))\n",
    "print(len(espc[4].data[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
